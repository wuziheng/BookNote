# 第一章　概论

### 引言

RISC设计：１.指令并行（流水线和多指令发射）　２缓存的使用

03年开始（单核cpu不再追求高性能，因为功耗是频率的平方需求）：处理器性能的提高从单纯依赖指令级并行（ILP）转向数据级并行（DLP）和线程级（TLP）并行.ILP编译器和硬件隐式开发的，但DLP和TLP则是显式并行，需要调整程序的结构才能完成，大多数情况下会成为程序员的主要新增负担



### 计算机分类

| 特征              | 个人移动设备         | 台式机         | 服务器             | 集群               | 嵌入式          |
| --------------- | -------------- | ----------- | --------------- | ---------------- | ------------ |
| 系统价格(us dollar) | 100~1000       | 300~2500    | 5000~10000000   | 100000~200000000 | 10~100000    |
| 微处理器价格          | 10~100         | 50~500      | 200~2000        | 50~250           | 0.01~100     |
| 关键系统设计问题        | 成本，能耗，媒体性能，响应率 | 性价比，能耗，图形性能 | 吞吐量，可用性，可扩展性，能耗 | 性价比，吞吐量，能耗均衡性    | 价格，能耗，应用的特有性 |

*集群* 　集群和服务器的一大区别在于，集群多半是通过软件层来沟通数万台廉价的组件实现整体的行为；而服务器则是集成计算机硬件来实现的。同时集群和超算也有着很大的不同，在于集群的运算需求耦合度是松散的，更强调互动，大规模存储，可靠性和外网带宽，而超算一般的需求则是大型的通信密集的程序，往往会不间断高性能计算运行很长时间。

*嵌入式* 　嵌入式的使用场景非常广泛而且具有多样性，主要目标通常是以最低价格满足性能需求，而不是更高的价格来获取更高的性能（这点和其他的四种是很不相同的）。



### 并行度与并行体系结构

1. DLP：数据级并行，允许同时操作许多数据项
2. TLP：任务级并行，允许创建一些能够单独处理但大量采用并行方式执行的工作任务。

主要实现起来有几种方式：编译器实现的流水线，GPU，多线程

那么区分下来的并行体系结构有如下几种：

1. SISD：单处理器，单指令流，单数据流
2. SIMD：单指令流，多数据流，同一个指令由多个不同数据流的处理器执行，每个处理器都有自己的数据储存器（MD）,但只有一个指令存储器和控制处理器(GPU)。
3. MISD：多指令流，单数据流，暂时还没有这个类型的商用多处理器
4. MIMD：每个处理器都提取自己的指令，任务级别的并行，比SIMD更加灵活（也更贵）。同时也要开发数据级并行。（比如集群和仓库级）



### 计算机体系结构定义

体系结构的设计包括：指令集设计，功能组织，逻辑设计，实现方式（IC设计，包装，电池，冷却），需要熟悉的内容，从编译器到操作系统到逻辑设计与包装等技术。



**指令集体系结构（ISA）**

代指程序员可以看到的实际指令集，区分软件和硬件的界限，比如80x86,ARM,MIPS等等,他们主要的区别是从一下７个方面：

- 寄存器和存储器
- 存储器寻址（字节寻址，对齐or不对齐）
- 寻址模式（立即数，寄存器，位移，pc计数器，等等）
- 操作数类型（8位，１６位，３２位，６４位）、
- 操作指令（数据传输指令，算术逻辑指令，控制指令，浮点指令）
- 控制流指令（如何跳转到分支指令和存放位置）
- 编码（固定长度（ARM,MIPS）和可变长度（x0x86））



**计算机体系结构：组成与硬件**

- 集成电路逻辑技术（摩尔定律）
- 半导体DRAM（动态随机访问存储器，早两年我还会自己用mos管设计这个）
- 半导体闪存（电可擦除只读存储器）
- 磁盘技术（这一技术是服务器和仓库级存储的核心技术）
- 网络技术



**性能趋势：带宽胜过延迟**

**能耗指标更为准确:　能耗＝功耗×时间**

**模块可靠性**:MTTF,平均无故障时间，MTTR是平均修复时间，可用性＝（MTTF）/（MTTF+MTTR）



### 计算机设计的量化原理

- 充分利用并行（分布式或者是流水线）
- 局域性原理
- 重点关注常见情形
- Amdahl定律，描述了汇报递减的规律，指定了某一部分的升级资源应当与这一部分原来话费的时间成比例
- 处理器性能取决于：时钟频率（硬件），指令的时钟周期（组成与指令集），指令数（指令集与编译器技术）





# 第二章　存储器层次结构设计

### 存储器结构基础

- 基本结构：缓存块与组相连（多个块构成一个组，块移入缓存首先映射到一个组内）
- 缓存写入（直写：更新缓存就直接写入存储器　和　回写：需要替换缓存块时才把他在存储器中更新）
- 衡量指标：缺失率（未能找到预期目标的缓存访问所占的比例）



我们在研究高缺失率的原因时主要有以下三个部分：

- 强制：对于一个数据块的第一次访问，这个块不可能在缓存中，所以要调块进入缓存
- 容量：如果缓存不能包含程序运行期间所有的块，我们就会进行换入换出
- 冲突：？？？
- 一致性：多核多线程情况下保持多个缓存的一致性



*度量标准：* 存储器平均访问时间　＝　命中时间　＋　缺失率　x　缺失代价

命中时间：　缓存中命中目标花费的时间

缺失代价：　内存中替换快的时间

带宽和功耗：　多线程，高吞吐量需求下的考虑

#### 六种基本的缓存优化方法：

- 增大块以降低缺失率：利用空间局域性原理，可以减少缺失率，但代价是增加缺失代价（换块时间）
- 增大缓存以降低缺失率：增加成本和功率
- 提高相关联程度可以减少冲突缺失：延长命中时间为代价的，也会增大功耗
- 多级缓存降低缺失代价
- 为读取缺失指定高于写入操作的优先级：先读后写
- 在缓存索引期间避免地址转换：缩短命中时间






### 缓存性能的十种高级优化方法

首先是总结缓存优化度量指标：**命中时间／缺失率／缺失代价／缓存带宽／功耗**

* 缩短命中时间：　小而简单的第一级缓存和路预测
* 增加缓存带框：　流水化缓存，多组缓存，无阻塞缓存
* 降低缺失代价：　关键字优化，合并写缓存区域
* 降低缺失率：　编译器优化
* 通过并行降低却是代价或者缺失率：　硬件预取和编译器预取


####小而简单的一级缓存

无论是在访存时间还是在功耗以及设计简单上来说，一级缓存都选取较少的组联结。

#### 路预测

缓存中另外保存一些位，用于预测下一次缓存优先访问组中的路或块。对于一个两路组相联的缓存，预测准确度超过90%,四路的超过80%.能提升访问速度，降低访存功耗。 **这里额外的开销是改变路预测器需要增加一个时钟周期的延迟，同时增大了流水化的难度**

#### 无阻塞缓存(?)

在允许乱序执行的流水化计算机中，处理器不必为一次数据缓存缺失而停顿。无阻塞缓存允许在一次缺失期间继续提供缓存命中。例如等待数据缓存返回缺失数据时，处理器可以继续从指令缓存中提取指令。

**限制使用无阻塞缓存的因素主要是缺失流的居于性和对访问请求的最大带宽**

#### 多种缓存提高带宽

可以把缓存划分为几个相互独立／支持同时访问的缓存组。

#### 关键字优化和提前重启降低缺失代价

人们观测到处理器某一时刻仅需要缓存块的一个字，一旦载入这个字，就重启处理器。关键字优先：首先从存储器中请求缺失的字。　直接发送给处理器

#### 合并写缓冲区

准备写缓冲区，在写缓冲区准备将字写到存储器时，处理器继续自己的工作。如果写缓冲区中包含其他经过修改的块，则检查它们的地址是否能够与缓冲区中的地址匹配拼接，如果有则可以合并。（可以提升写缓冲区的利用率）

#### 编译器优化低缺失率

例如：

- 嵌套循环里会以非连续顺序访问存储器中的顺序，只要交换一下嵌套顺序则可以。
- 分块　计算矩阵乘法。

#### 指令和数据的硬件预取

通常，处理器在一次缺失时提取两个块，被请求块和笑一个相邻块。请求块放在指令缓存中，预取的则放在缓冲区。

#### 编译器控制预取

基于编译器的优化了～很hack





### 存储器的技术优化

除了缓存可以用来缩小cpu和dram之间的差距，我们也需要革新dram的技术。几乎所有计算机都采用DRAM作为主存储器，SRAM作为缓存。

- *回顾SRAM技术(static ram)*: 6个晶体管保存一位数据，需要很少的功率来维持电荷。DRAM是动态的，要求读取数据后写回，而SRAM则不需要。
- *回顾DRAM技术(dynamic ram)*: 仅仅使用一个晶体管来存储一位数据，读取后会破坏原信息，必须要写回。一般内存都是以DIMM(双列直插式存储模块)的封转面世.
- *回顾GDRAM（graphic dynamic ram）*: 图形数据特殊DRAM,满足图形处理器中的高带宽需求。接口更宽
- *回顾EEPROM（flash）*: 掉电可以保存。静态功耗很低。速度比sdram慢，但比磁盘块。

在提升可靠上，可以用进行奇偶校验，ECC,chipkill等技术进行检验。





# 第三章　指令级并行及开发

### 概念与挑战

**ILP**(指令级并行)：

* 依靠硬件来帮助动态发现和开发并行
* 依靠软件技术在编译器静态发现并行。

一个流水化处理器的CPI（cycle per instruction）（每条指令占用的周期数）值等于基本CPI与因为各种停顿而耗费的全部周期之和：

　　　　　　　　流水线CPU = 理想流水线CPI+结构化停顿＋数据冒险停顿＋控制停顿

基本块可以利用的并行数非常有限，一般为了真正提高性能，我们必须跨越多个基本块开发ILP.

- **循环级并行**：**最简单，最为常见**的做法是在循环的各个迭代之间开发并行。
- 数据相关与冒险:我们必须判断哪些指令可以并行执行，那些是必须按序执行的。其中提到数据相关：（真）数据相关，名称相关，控制相关。数据相关传递了３点信息：１.冒险的可能性，２．计算结果必须遵循的顺序，３．可开发并行度的上限。
- 名称相关：当两条指令使用相同的寄存器或存储器位置，但与该名称相关的指令间没有数据流动时，就会发生名称相关。没有数据流动的情况下可以通过改变名称消除相关
- 数据冒险：RAW(写后读)，WAW(写后写)，WAR(读后写)
- 控制相关：控制相关不是必须保持的关键特性。**异常行为和数据流**才是.通过保持数据相关和控制相关也就保护了这两种特性。比如跳转不改变之后的数据相关就可以先执行下面的。



### ILP基本编译器技术

保持流水线满载，必须找出可以在流水线中重叠的不相关指令序列。为了避免流水线停顿，必须将相关指令与源指令的执行隔开一定的时间周期。这一间隔应当等于源指令的流水线延迟。

对于循环来说：如果循环开销大于循环体内指令的开销，我们可以把循环展开（多个循环体运算靠一个循环开销维护），提高调度效率。同时考虑到流水线深度，还可以减少停顿。

